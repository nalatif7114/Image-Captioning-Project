{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504248a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\CODE\\Image-Captioning-Project\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SETUP & IMPORT\n",
    "# ============================================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cek GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# PATH CONFIGURATION\n",
    "# Pastikan path ini sesuai dengan struktur folder Anda\n",
    "IMAGE_DIR = r'D:\\CODE\\Image-Captioning-Project\\data\\Images'\n",
    "OUTPUT_DIR = r'D:\\CODE\\Image-Captioning-Project\\data\\Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fadf52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\CODE\\Image-Captioning-Project\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\CODE\\Image-Captioning-Project\\.venv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 82s 1us/step\n",
      "Model Loaded.\n",
      "Output Shape expected: (None, 8, 8, 2048)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL DEFINITION\n",
    "# ============================================================\n",
    "def load_inception_model():\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    \n",
    "    # Kita ambil input model dan output layer terakhir\n",
    "    new_input = base_model.input\n",
    "    hidden_layer = base_model.layers[-1].output \n",
    "\n",
    "    model = Model(inputs=new_input, outputs=hidden_layer)\n",
    "    return model\n",
    "\n",
    "model = load_inception_model()\n",
    "print(\"Model Loaded.\")\n",
    "print(f\"Output Shape expected: (None, 8, 8, 2048)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783d26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPROCESSING FUNCTION\n",
    "# ============================================================\n",
    "def load_image(image_path):\n",
    "    # Baca file gambar\n",
    "    img = tf.io.read_file(image_path)\n",
    "    # Decode jpeg (3 channels)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Resize wajib ke 299x299 untuk InceptionV3\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    # Preprocess (scaling -1 to 1)\n",
    "    img = preprocess_input(img)\n",
    "    return img, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c41a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images to process: 8091\n",
      "Starting Feature Extraction\n",
      "Features will be saved as .npy files next to original images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [23:30<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXTRACTION LOOP\n",
    "# ============================================================\n",
    "\n",
    "# Ambil semua file jpg di folder\n",
    "all_images = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.jpg')]\n",
    "# Hapus duplikat dan sort\n",
    "encode_train = sorted(set(all_images))\n",
    "\n",
    "print(f\"Total images to process: {len(encode_train)}\")\n",
    "\n",
    "# Buat TF Dataset agar loading cepat & efisien memori\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
    "image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Batching: Proses 16/32 gambar sekaligus\n",
    "image_dataset = image_dataset.batch(32)\n",
    "\n",
    "print(\"Starting Feature Extraction\")\n",
    "print(\"Features will be saved as .npy files next to original images.\")\n",
    "\n",
    "for batch_imgs, batch_paths in tqdm(image_dataset):\n",
    "    # Forward pass ke model\n",
    "    batch_features = model(batch_imgs)\n",
    "    \n",
    "    # Reshape dari (Batch, 8, 8, 2048) menjadi (Batch, 64, 2048)\n",
    "    batch_features = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "\n",
    "    # Simpan per file\n",
    "    for bf, path in zip(batch_features, batch_paths):\n",
    "        path_of_feature = path.numpy().decode(\"utf-8\")\n",
    "        # Nama file output: image_name.jpg.npy\n",
    "        np.save(path_of_feature + '.npy', bf.numpy())\n",
    "\n",
    "print(\"Extraction Completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
